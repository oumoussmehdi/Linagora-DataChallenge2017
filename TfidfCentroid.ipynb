{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer, CountVectorizer\n",
    "import sklearn.preprocessing as pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load some of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = 'C:\\\\Users\\\\hbnp5049\\\\PycharmProjects\\\\untitled\\\\'# fill me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "testing_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def email_sender_df(training):\n",
    "    email_sender = {}\n",
    "    for index, series in training.iterrows():\n",
    "        row = series.tolist()\n",
    "        sender = row[0]\n",
    "        ids = row[1:][0].split(' ')\n",
    "        for id in ids:\n",
    "            email_sender[int(id)] = sender\n",
    "    es_df = pd.DataFrame.from_dict(email_sender, orient='index').reset_index()\n",
    "    es_df.rename(columns={'index': 'mid', 0: 'sender'}, inplace=True)\n",
    "    print('df shape',es_df.shape)\n",
    "    return es_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape (43613, 2)\n"
     ]
    }
   ],
   "source": [
    "es_df = email_sender_df(training)\n",
    "train_df = pd.merge(training_info,es_df,on='mid',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape (2362, 2)\n"
     ]
    }
   ],
   "source": [
    "es_test_df = email_sender_df(testing)\n",
    "test_df = pd.merge(testing_info,es_test_df,on='mid',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_per_sender = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_results(predictions_per_sender):\n",
    "    #m.to_csv(r'C:\\Users\\hbnp5049\\PycharmProjects\\untitled\\predictions.csv', header=mcols, index=None, sep=',')\n",
    "    with open(path_to_data + 'predictions_tfidfClassifier.txt', 'w') as my_file:\n",
    "        my_file.write('mid,recipients' + '\\n')\n",
    "        for sender, preds in predictions_per_sender.items():\n",
    "            ids = preds[0]\n",
    "            preds = preds[1]\n",
    "            for index, my_preds in enumerate(preds):\n",
    "                my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def body_preprocessing(sender, X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                             max_df=0.5,\n",
    "                             stop_words='english',\n",
    "                             analyzer = 'word',\n",
    "                             max_features=103,\n",
    "                            norm = 'l2')\n",
    "    X_train_bin = vectorizer.fit_transform(X_train['body'].values)\n",
    "    \n",
    "    Centroids = {}\n",
    "    for index, series in X_train.iterrows():\n",
    "        row = series.tolist()\n",
    "        recipients = row[3]\n",
    "        for r in recipients:\n",
    "            mu = X_train_bin[index]\n",
    "            if r not in Centroids:\n",
    "                Centroids[r] = mu\n",
    "            else:\n",
    "                Centroids[r] += mu\n",
    "    \n",
    "    #********Testing*****************\n",
    "    X_test_bin = vectorizer.transform(X_test['body'])\n",
    "    ids = []\n",
    "    preds = []\n",
    "    for index, series in X_test.iterrows():\n",
    "        id = X_test['mid'][index]\n",
    "        temp = {}\n",
    "        for k in Centroids.keys():\n",
    "            temp[k] = cosine_similarity(X_test_bin[index], Centroids[k])  \n",
    "        sorted_temp = sorted(temp.items(), key = operator.itemgetter(1), reverse = True)\n",
    "        predictions = sorted_temp[:10]\n",
    "        predictions = [elt[0] for elt in predictions]\n",
    "        ids.append(id)\n",
    "        preds.append(predictions)\n",
    "        print(id, predictions)\n",
    "    predictions_per_sender[sender]=[ids, preds]\n",
    "    #print(predictions_per_sender)\n",
    "    output_results(predictions_per_sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommendation(sender):\n",
    "    # take the subset where x is the sender\n",
    "    X_train = train_df[train_df['sender']==sender]\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    # convert and clearn the column recipients\n",
    "    for index, row in X_train.iterrows():\n",
    "        recipients = row['recipients'].split() \n",
    "        recipients = [rec for rec in recipients if '@' in rec]\n",
    "        X_train['recipients'][index] = recipients\n",
    "    X_test = test_df[test_df['sender']==sender]\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    # Focus only on a sender case\n",
    "    body_preprocessing(sender, X_train, X_test)\n",
    "    predictions_per_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sender in test_df['sender']:\n",
    "    recommendation(sender)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
