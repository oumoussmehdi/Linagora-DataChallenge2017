{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#Retrieve the messages associated to each sender\n",
    "training_info = pd.read_csv(\"/Users/Narjes/Documents/Paris-Saclay University/Learning for Text and Graph Data/Data competition 2017/training_info.csv\")\n",
    "training_set = pd.read_csv(\"/Users/Narjes/Documents/Paris-Saclay University/Learning for Text and Graph Data/Data competition 2017/training_set.csv\")\n",
    "test_set = pd.read_csv(\"/Users/Narjes/Documents/Paris-Saclay University/Learning for Text and Graph Data/Data competition 2017/test_set.csv\")\n",
    "test_info = pd.read_csv(\"/Users/Narjes/Documents/Paris-Saclay University/Learning for Text and Graph Data/Data competition 2017/test_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a message file for each sender\n",
    "for k in range(len(training_set)):\n",
    "    sender_msgs = []\n",
    "    mid_list = training_set['mids'][k].split(' ')\n",
    "    for i in range(len(mid_list)):\n",
    "        mid_list[i] = int(mid_list[i])\n",
    "\n",
    "    for j in range(len(training_info)):\n",
    "        if training_info['mid'][j] in mid_list:\n",
    "            if len(sender_msgs) == 0:\n",
    "                sender_msgs = pd.DataFrame(training_info.loc[[j]])\n",
    "            else:\n",
    "                sender_msgs = sender_msgs.append(pd.DataFrame(training_info.loc[[j]]))\n",
    "    print(k)\n",
    "    file_name =  (training_set['sender'][k].split('@'))[0] + \".csv\"\n",
    "    sender_msgs.to_csv(file_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karen.buckley.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Narjes\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amr.ibrahim.csv\n",
      "andrea.ring.csv\n",
      "sylvia.hu.csv\n",
      "phillip.platter.csv\n",
      "richard.shapiro.csv\n",
      "megan.parker.csv\n",
      "david.forster.csv\n",
      "mike.maggi.csv\n",
      "justin.rostant.csv\n",
      "marcus.nettelton.csv\n",
      "kathleen.carnahan.csv\n",
      "grace.rodriguez.csv\n",
      "hunter.s.shively.csv\n",
      "sandra.f.brawner.csv\n",
      "l..nicolay.csv\n",
      "mark.whitt.csv\n",
      "james.derrick.csv\n",
      "darrell.schoolcraft.csv\n",
      "l..denton.csv\n",
      "cheryl.johnson.csv\n",
      "scott.neal.csv\n",
      "chris.germany.csv\n",
      "eric.bass.csv\n",
      "larry.f.campbell.csv\n",
      "lynn.blair.csv\n",
      "nancy.sellers.csv\n",
      "harry.kingerski.csv\n",
      "m..forney.csv\n",
      "stacey.w.white.csv\n",
      "rick.buy.csv\n",
      "matt.smith.csv\n",
      "dutch.quigley.csv\n",
      "greg.piper.csv\n",
      "stanley.horton.csv\n",
      "liz.taylor.csv\n",
      "jason.williams.csv\n",
      "taylor.csv\n",
      "alex.csv\n",
      "mary.cook.csv\n",
      "m..schmidt.csv\n",
      "joe.stepenovitch.csv\n",
      "mike.carson.csv\n",
      "paul.kaufman.csv\n",
      "sheila.glover.csv\n",
      "jane.tholt.csv\n",
      "monika.causholli.csv\n",
      "jim.schwieger.csv\n",
      "andy.zipper.csv\n",
      "janel.guerrero.csv\n",
      "kim.ward.csv\n",
      "lisa.mellencamp.csv\n",
      "beth.cherry.csv\n",
      "david.port.csv\n",
      "kevin.m.presto.csv\n",
      "mike.grigsby.csv\n",
      "julie.armstrong.csv\n",
      "wsmith.csv\n",
      "martin.cuilla.csv\n",
      "phillip.m.love.csv\n",
      "rahil.jafry.csv\n",
      "tori.kuykendall.csv\n",
      "kimberly.hillis.csv\n",
      "bob.shults.csv\n",
      "michelle.cash.csv\n",
      "vkaminski.csv\n",
      "james.d.steffes.csv\n",
      "marie.heard.csv\n",
      "jean.mrha.csv\n",
      "patrice.l.mims.csv\n",
      "peter.keohane.csv\n",
      "andrew.edison.csv\n",
      "suzanne.adams.csv\n",
      "shona.wilson.csv\n",
      "schwabalerts.marketupdates.csv\n",
      "holden.salisbury.csv\n",
      "w..cantrell.csv\n",
      "john.zufferli.csv\n",
      "alan.aronowitz.csv\n",
      "paul.y barbo.csv\n",
      "brad.mckay.csv\n",
      "stephanie.miller.csv\n",
      "jbennett.csv\n",
      "sara.shackleton.csv\n",
      "lorna.brennan.csv\n",
      "mark.mcconnell.csv\n",
      "susan.scott.csv\n",
      "stephanie.panus.csv\n",
      "karen.denne.csv\n",
      "mark.palmer.csv\n",
      "jonathan.mckay.csv\n",
      "becky.spencer.csv\n",
      "joannie.williamson.csv\n",
      "alan.comnes.csv\n",
      "paul.d.thomas.csv\n",
      "chris.dorland.csv\n",
      "ginger.dernehl.csv\n",
      "cindy.stark.csv\n",
      "david.portz.csv\n",
      "tanya.rohauer.csv\n",
      "stephanie.sever.csv\n",
      "sally.beck.csv\n",
      "keegan.farrell.csv\n",
      "kenneth.thibodeaux.csv\n",
      "christian.yoder.csv\n",
      "brian.redmond.csv\n",
      "russell.diamond.csv\n",
      "john.lavorato.csv\n",
      "ben.jacoby.csv\n",
      "britt.davis.csv\n",
      "holly.keiser.csv\n",
      "michael.tribolet.csv\n",
      "errol.mclaughlin.csv\n",
      "heather.dunton.csv\n",
      "christina.valdez.csv\n",
      "jennifer.thome.csv\n",
      "jason.wolfe.csv\n",
      "tim.belden.csv\n",
      "mark.greenberg.csv\n",
      "fletcher.j.sturm.csv\n",
      "c..giron.csv\n",
      "barry.tycholiz.csv\n",
      "amy.fitzpatrick.csv\n",
      "c..williams.csv\n",
      "enron_update.csv\n"
     ]
    }
   ],
   "source": [
    "submission_data = pd.DataFrame(columns = ('mid', 'recipients'))\n",
    "### Retrieve the data of all senders\n",
    "for i in range(len(test_set)):\n",
    "    file_name =  (training_set['sender'][i].split('@'))[0] + \".csv\"\n",
    "    print(file_name)\n",
    "    df = pd.read_csv(file_name)\n",
    "    # Transform the message to bag of words\n",
    "    # We can more processing on bodies to increase the relevance of the choosen words\n",
    "    # Eliminate stop words\n",
    "    for j in range(len(df)):\n",
    "        bag = ' '.join([word for word in df['body'][j].split('\\t')])\n",
    "        df['body'][j] = ' '.join([word for word in bag.split(' ') if not (len(word) < 4 or  word in stopwords.words(\"english\"))])\n",
    "    # Retrieve the test message of the sender\n",
    "    msgs_id = [int(mid) for mid in test_set['mids'][i].split(' ')]\n",
    "    ind = 0                           \n",
    "    for mid in msgs_id:\n",
    "    # Apply tfidf\n",
    "        recipients_corpus = []\n",
    "        submission_dic = dict()\n",
    "        corpus = [email for email in df['body']]\n",
    "        # Get the message and add it to the corpus\n",
    "        msg_test = test_info[test_info.mid == mid]\n",
    "        test = msg_test['body'][msg_test.index[0]]\n",
    "        test = ' '.join([word for word in test.split('\\t')])\n",
    "        test = ' '.join([word for word in test.split(' ') if not (len(word) < 4 or word in stopwords.words(\"english\"))])\n",
    "        corpus.append(test)\n",
    "        # TFIDF\n",
    "        vectorizer = TfidfVectorizer(min_df=1)\n",
    "        matrix = vectorizer.fit_transform(corpus)\n",
    "        recipients_list = []\n",
    "        add_rec = []\n",
    "        matrix_test = matrix[len(corpus) - 1 : len(corpus)]       \n",
    "        cosine_similarities = linear_kernel(matrix_test, matrix).flatten()\n",
    "        related_docs_indices = cosine_similarities.argsort()[:-32:-1]\n",
    "        for k in range(len(related_docs_indices)):\n",
    "            if related_docs_indices[k] == len(corpus) - 1:\n",
    "                index = k\n",
    "        related_docs_indices = np.delete(related_docs_indices, index)\n",
    "        for idx in related_docs_indices:\n",
    "            recipients_list.append(df['recipients'][idx].split(' '))\n",
    "            #For each email\n",
    "            dic_recp = dict()\n",
    "            for rep_list in recipients_list:\n",
    "                for em_add in rep_list:\n",
    "                    if em_add not in dic_recp.keys():\n",
    "                        dic_recp[em_add] = cosine_similarities[related_docs_indices[recipients_list.index(rep_list)]]\n",
    "                    else:\n",
    "                        dic_recp[em_add] += cosine_similarities[related_docs_indices[recipients_list.index(rep_list)]]\n",
    "        sorted_recep = sorted(dic_recp.items(), key=operator.itemgetter(1))\n",
    "        for rep_sim in reversed(sorted_recep[-11:-1]):\n",
    "            add_rec.append(rep_sim[0])\n",
    "        submission_dic['mid'] = [mid]\n",
    "        sub_add_list =' '.join([add for add in add_rec])\n",
    "#        print(sub_add_list)\n",
    "        submission_dic['recipients'] = [sub_add_list]\n",
    "        if submission_data.empty:\n",
    "            submission_data = pd.DataFrame(submission_dic)\n",
    "        else:\n",
    "            submission_data = submission_data.append(pd.DataFrame(submission_dic))\n",
    "#        print(submission_data)\n",
    "submission_data.to_csv('submission.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
